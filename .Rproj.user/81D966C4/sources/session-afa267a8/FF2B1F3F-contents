nn = function(formula, data, epochs = 100, batch_size = 4, validation_split = 0.2, units = c(8, 4)) {
  require(keras)
  require(tensorflow)
  require(reticulate)
  require(dplyr)
  
  # Suppress TensorFlow warnings
  if (requireNamespace("tensorflow", quietly = TRUE)) {
    tryCatch({
      tensorflow::tf$get_logger()$setLevel('ERROR')
      tensorflow::tf$compat$v1$logging$set_verbosity(tensorflow::tf$compat$v1$logging$ERROR)
    }, error = function(e) {})
  }
  
  # Extract response and predictors from formula
  
  tt = terms(formula, data = data)
  mf = model.frame(tt, data = data)
  y = model.response(mf)
  x = model.matrix(tt, data = data)[, -1]  # drop intercept
  
  # Force proper types
  x = as.matrix(x)
  y = as.numeric(y)
  
  
  
  # Remove intercept column if present
  if (colnames(x)[1] == "(Intercept)") x = x[, -1]
  
  # Normalize predictors
  x_means = colMeans(x)
  x_sds = apply(x, 2, sd)
  x_scaled = scale(x, center = x_means, scale = x_sds)
  
  # Define model
  model = keras_model_sequential()
  model %>% layer_dense(units = units[1], activation = "relu", input_shape = ncol(x_scaled))
  for (i in 2:length(units)) {
    model %>% layer_dense(units = units[i], activation = "relu")
  }
  model %>% layer_dense(units = 1)
  
  # Compile
  model %>% compile(
    loss = "mse",
    optimizer = optimizer_adam(),
    metrics = list("mean_absolute_error")
  )
  
  # Fit
  history = model %>% fit(
    x_scaled, y,
    epochs = epochs,
    batch_size = batch_size,
    validation_split = validation_split
  )
  
  return(list(model = model, history = history, x_means = x_means, x_sds = x_sds, formula = formula, x=x, y=y))
}

compute_permutation_importance = function(model, x_test, y_test, metric = "mean_absolute_error") {
  baseline = model %>% evaluate(x_test, y_test, verbose = 0)
  baseline_score = baseline[[metric]]
  
  importances = map_dbl(1:ncol(x_test), function(i) {
    x_perm = x_test
    x_perm[, i] = sample(x_perm[, i])  # permute column i
    perm_score = model %>% evaluate(x_perm, y_test, verbose = 0)
    perm_score[[metric]] - baseline_score  # increase in error = importance
  })
  
  tibble(
    variable = colnames(x_test),
    importance = importances
  ) %>%
    arrange(desc(importance))
}

plot_nn_effect = function(model, data, outcome, predictor) {
  require(tidyverse)
  
  # Separate predictors and outcome
  predictors = data %>% select(-all_of(outcome))
  y = data[[outcome]]
  
  # Save means and SDs for rescaling
  x_means = colMeans(predictors)
  x_sds = apply(predictors, 2, sd)
  
  # Generate a sequence of values for the focal predictor
  predictor_seq = seq(min(predictors[[predictor]]), max(predictors[[predictor]]), length.out = 50)
  
  # Create test data where all variables are at their mean
  x_test_orig = matrix(rep(x_means, each = 50), nrow = 50) %>%
    data.frame() %>%
    setNames(names(predictors))
  
  # Replace focal predictor with sequence
  x_test_orig[[predictor]] = predictor_seq
  
  # Standardize the test set using original means/SDs
  x_test_scaled = scale(x_test_orig, center = x_means, scale = x_sds)
  
  # Generate predictions
  preds = model %>% predict(x_test_scaled)
  
  # Actual (raw) data for scatterplot
  actual_data = data %>%
    select(all_of(predictor), all_of(outcome)) %>%
    rename(x = all_of(predictor), y = all_of(outcome))
  
  # Predictions for line plot
  prediction_data = tibble(
    x = predictor_seq,
    y = as.numeric(preds)
  )
  
  # Combine and plot
  ggplot() +
    geom_point(data = actual_data, aes(x = x, y = y), alpha = 0.5) +
    geom_line(data = prediction_data, aes(x = x, y = y), color = "blue", size = 1.2) +
    labs(
      x = predictor,
      y = outcome,
      title = glue::glue("Effect of {predictor} on Predicted {outcome}")
    ) +
    theme_minimal()
}


