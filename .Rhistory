rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
compare_fits(fire~civilian_deserve, data=d, nn_model$model, alpha = .1)
pred.values
str(pred.values)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model$model, alpha = .1)
factor_cols
# Handle categorical variables
factor_cols = sapply(pred.values, is.factor)
pred.values[factor_cols] = lapply(pred.values[factor_cols], function(x) {
if(is.ordered(x)) as.numeric(x) else as.numeric(x) - 1
})
pred.values
# Separate features and target (assuming target is first column)
target_col = names(pred.values)[1]
target_col
X = pred.values[, !names(pred.values) %in% target_col, drop = FALSE]
y = pred.values[[target_col]]
# Convert to matrix and scale
X_matrix = as.matrix(X)
X_scaled = scale(X_matrix)
# Make predictions
predictions = predict(model, X_scaled)
reticulate::py_last_error()
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model$model, alpha = .1)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model$model, alpha = .1)
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
traceback()
class(nn_model)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
attributes(model)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
names(model)
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
model
names(model)
model$var_names
attr(model, "original_data_vars")
attributes(model)
devtools::load_all(".")
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
devtools::load_all(".")
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
model$var_names
model$original_names
nn_model = model
model = model$model
# Get the original data variable names (before model.matrix expansion)
original_data_vars = attr(model, "original_data_vars")
response = attr(model, "response_var")
if (!is.null(original_data_vars) && !is.null(response)) {
# Remove the response variable from predictors
predictors = setdiff(original_data_vars, response)
return(list(predictors = predictors, response = response))
}
# Fallback if not available
predictors = attr(model, "var_names")
if (is.null(predictors)) {
input_shape = model$input_shape
n_predictors = if(is.list(input_shape)) input_shape[[2]] else input_shape[2]
predictors = paste0("X", 1:n_predictors)
}
if (is.null(response)) response = "Y"
response
predictors
# Get the original data variable names (before model.matrix expansion)
original_data_vars = attr(model, "original_data_vars")
response = attr(model, "response_var")
original_data_vars
response
!is.null(original_data_vars)
!is.null(response)
original_data_vars
response
if (!is.null(original_data_vars) && !is.null(response)) {
# Remove the response variable from predictors
predictors = setdiff(original_data_vars, response)
return(list(predictors = predictors, response = response))
}
predictors
is.null(predictors)
original_data_vars
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
traceback()
devtools::load_all(".")
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
# extract data
pred.values = model$x
pred.values
# Handle categorical variables
factor_cols = sapply(pred.values, is.factor)
pred.values[factor_cols] = lapply(pred.values[factor_cols], function(x) {
if(is.ordered(x)) as.numeric(x) else as.numeric(x) - 1
})
# Separate features and target (assuming target is first column)
target_col = names(pred.values)[1]
X = pred.values[, !names(pred.values) %in% target_col, drop = FALSE]
pred.values
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
pred.values
str(pred.values)
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
target_col
pred.values
model$y
# Separate features and target (assuming target is first column)
target_col = model$y
X = pred.values[, !names(pred.values) %in% target_col, drop = FALSE]
pred.values
# extract data
pred.values = model$x
# Handle categorical variables
factor_cols = sapply(pred.values, is.factor)
pred.values
pred.values[factor_cols] = lapply(pred.values[factor_cols], function(x) {
if(is.ordered(x)) as.numeric(x) else as.numeric(x) - 1
})
str(pred.values)
# extract data
pred.values = model$x
str(pred.values)
# extract data
pred.values = model$x
str(pred.values)
# Handle categorical variables
factor_cols = sapply(pred.values, is.factor)
pred.values[,factor_cols] = lapply(pred.values[factor_cols], function(x) {
if(is.ordered(x)) as.numeric(x) else as.numeric(x) - 1
})
# extract data
pred.values = model$x
str(pred.values)
# Handle categorical variables
factor_cols = sapply(pred.values, is.factor)
pred.values[,factor_cols] = lapply(pred.values[,factor_cols], function(x) {
if(is.ordered(x)) as.numeric(x) else as.numeric(x) - 1
})
model$y
# extract data
pred.values = model$x
# Separate features and target
X = model$x
y = model$y
X
# Convert to matrix and scale (X is already a matrix)
X_scaled = scale(X)
# Make predictions
predictions = predict(model, X_scaled)
# Make predictions
predictions = predict(model$model, X_scaled)
predictions
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
rlang::last_trace()
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
str(k)
predictions
predictions = data.frame(predictions)
predictions
model2
predictions$model = deparse(substitute(model1))
predictions
both_models_identical = identical(model1, model2)
if (!both_models_identical) {
predictions2 = get_fitted(model2, re=re, pred.type=pred.type, report.se=F)
predictions2$model = deparse(substitute(model2))
predictions = rbind(predictions, predictions2)
k = rbind(k, k)
}
k$prediction = predictions$prediction
k$model      = predictions$model
# get predicted values
pred.values = get_plotted_line(data=k, formula=formula, model=model1, ...)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1)
compare_fits(fire~civilian_deserve, data=d, nn_model, alpha = .1) %>%
logistic_overlay()
estimates(nn_model)
compare_fits(fire~civilian_deserve + Guilty, data=d, nn_model, alpha = .1) %>%
logistic_overlay()
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1)
devtools::load_all(".")
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, rf_mod, nn_model, alpha = .1) %>%
logistic_overlay()
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, rf_mod, nn_model, alpha = .1) %>%
logistic_overlay()
devtools::load_all(".")
devtools::load_all(".")
require(flexplot)
require(tidyverse)
require(party)
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
devtools::load_all(".")
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
k
get_fitted(model2, re=re, pred.values=k, pred.type=pred.type, report.se=F)
str(predictions)
str(predictions2)
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
traceback()
devtools::load_all(".")
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
require(flexplot)
require(tidyverse)
require(party)
devtools::load_all(".")
d_original = read.csv("~/Downloads/data/Study 4 for R.csv")
d = d_original %>%
select(-c(StartDate, Durationinseconds)) %>%
rename("enemy_deserve" = P1Des) %>%
rename("civilian_deserve" = P2Des) %>%
rename("acceptable" = Accept_1) %>%
rename("hospital_targets_legitimate" = TW_1) %>%
rename("hospital_never_target" = TW_2R) %>%
rename("responsiblity_us_vs_them" = TW_3) %>%
rename("alls_fair" = TW_4) %>%
rename("d.teleology" = TW_L3) %>%
rename("teleology" = TW_L4) %>%
rename("target_if_hiding" = TW_L5) %>%
rename("ok_no_advantage" = TW_L1) %>%
rename("ok_yes_advantage" = TW_L2) %>%
rename("fire" = Fire) %>%
select(-c(TotalWarBeliefs, Condition, acceptable, d.teleology)) %>%
mutate(Edu = factor(Edu, ordered=T),
Guilty = factor(Guilty)) %>%
drop_na()
mod_layers = function(model, input_dim) {
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = input_dim) %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = "sigmoid") # sigmoid for binary classification
}
nn_model = nn(fire~., data=d, layers = mod_layers,
loss = "binary_crossentropy",
metrics = c("accuracy", metric_auc()))
## now let's do a RF to find the best predictors
rf_mod = cforest(fire~., data=d)
compare_fits(fire~civilian_deserve, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve + Guilty, data=d, nn_model, alpha = .1) %>%
logistic_overlay()
compare_fits(fire~civilian_deserve | Guilty, data=d, nn_model, rf_mod, alpha = .1) %>%
logistic_overlay()
