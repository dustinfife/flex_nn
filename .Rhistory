combn(letters[1:4], 4)
combn(letters[1:4], 2)
combn(letters[1:4], 3)
combn(letters[1:4], 4)
combn(letters[1:4], 3)
expand.grid(1:3, 1:3, 1:3)
combn(1:3, 2)
combn(1:4, 4)
install.packages("combinat")
library(combinat)
x <- c(1, 2, 3)
all_orderings <- permn(x)
print(all_orderings)
sample(all_orderings, 3
)
?sample
?replicate
d = matrix(rnorm(10*100), nrow=100)
dim(d)
# full data shaps
# simulate some data
set.seed(123)
x = letters[1:10]
d = matrix(rnorm(10 * 100), nrow = 100) %>% data.frame() %>% setNames(x)
# a simple model (use your own instead)
mod = lm(a ~ ., data = d)
# number of bootstraps / permutations
iterations = 100
all_shap = matrix(0, nrow = iterations, ncol = length(x))
colnames(all_shap) = x
for (i in 1:iterations) {
# random feature ordering
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
all_shap[i, order_x] = shap_values
}
# random feature ordering
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
order_x
for (i in 1:iterations) {
# random feature ordering
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
all_shap[i, order_x] = shap_values
}
i
j
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
all_shap[i, order_x] = shap_values
shap_values
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
all_shap = matrix(0, nrow = iterations, ncol = length(x)) %>%
data.frame %>%
setNames(x)
all_shap
# random feature ordering
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
for (j in seq_along(order_x)) {
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[feature] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
all_shap[i, order_x] = shap_values
shap_values
shap_values = numeric(length(x))
shap_values
feature = order_x[j]
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
feature
j_num = 0
for (j in seq_along(order_x)) {
feature = order_x[j]
j_num = j_num + 1
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[j_num] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
# loop over features in the random order
j_num = 0
j_num = 0
for (j in seq_along(order_x)) {
feature = order_x[j]
j_num = j_num + 1
cat(j_num)
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[j_num] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
# loop over features in the random order
j = 1
j_num = 0
feature = order_x[j]
j_num = j_num + 1
cat(j_num)
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
j = 1
j_num = 0
for (j in seq_along(order_x)) {
feature = order_x[j]
j_num = j_num + 1
cat(j_num)
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[j_num] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
shap_values
features = c("x1", "x2", "x3")
model = function(x) { x["x1"]*2 + x["x2"]*3 + x["x3"]*4 }  # linear, for simplicity
# full data shaps
# simulate some data
set.seed(123)
x = letters[1:10]
d = matrix(rnorm(10 * 100), nrow = 100) %>% data.frame() %>% setNames(x)
# a simple model (use your own instead)
mod = lm(a ~ ., data = d)
# number of bootstraps / permutations
iterations = 100
all_shap = matrix(0, nrow = iterations, ncol = length(x)) %>%
data.frame %>%
setNames(x)
colnames(all_shap) = x
for (i in 1:iterations) {
# random feature ordering
order_x = sample(x)
# bootstrap sample
d_i = d[sample(nrow(d), replace = TRUE), ]
# independent baseline sample
baseline_data = d[sample(nrow(d), replace = TRUE), ]
# initial prediction (baseline)
y_prev = predict(mod, newdata = baseline_data)
shap_values = numeric(length(x))
# loop over features in the random order
j = 1
j_num = 0
for (j in seq_along(order_x)) {
feature = order_x[j]
j_num = j_num + 1
cat(j_num)
# replace this feature with real values from d_i
baseline_data[[feature]] = d_i[[feature]]
# predict new values
y_curr = predict(mod, newdata = baseline_data)
# compute marginal contribution
shap_values[j_num] = mean(y_curr - y_prev)
# update y_prev for next iteration
y_prev = y_curr
}
all_shap[i, order_x] = shap_values
}
# average contribution of each variable
shap_global = colMeans(all_shap)
shap_global
round(shap_global, 3)
# SpinCraft setup
rooms <- c("living room", "kitchen", "dad's room", "bathroom", "kids room", "closet(s)")
purpose <- c("organizer", "container", "decoration",
"an art piece", "hook or hanger", "sign or label", "display stand",
"caddy or carrier", "dispenser", "shelf", "divider or separator")
materials <- c("wood", "screw", "tape", "plastic", "clay", "cloth", "paint")
spin_craft <- function(team_names) {
n_teams <- length(team_names)
if (n_teams > length(rooms) || n_teams > length(purpose) || n_teams > length(materials)) {
stop("Not enough unique items in one or more categories for the number of teams.")
}
set.seed(Sys.time())  # fresh randomness
sampled_rooms <- sample(rooms, n_teams)
sampled_purposes <- sample(purpose, n_teams)
sampled_materials <- sample(materials, n_teams)
results <- mapply(function(team, room, task, material) {
glue::glue("
ðŸ”§ **{team}** has been summoned by the ancient overlords of Tablith! Their quest:
â€¢ **Purpose:** Build a {task}
â€¢ **Location:** For the {room}
â€¢ **Material Constraint:** Must include {material}
May their glue guns be swift and their designs worthy.")
},
team = team_names,
room = sampled_rooms,
task = sampled_purposes,
material = sampled_materials,
SIMPLIFY = TRUE)
cat(paste(results, collapse = "\n\n"))
}
spin_craft(c("Just Ethan (actually totally 100% for real this time"))
# SpinCraft setup
rooms <- c("living room", "kitchen", "dad's room", "bathroom", "kids room", "closet(s)")
purpose <- c("organizer", "container", "decoration",
"an art piece", "hook or hanger", "sign or label", "display stand",
"caddy or carrier", "dispenser", "shelf", "divider or separator")
materials <- c("wood", "screw", "tape", "plastic", "clay", "cloth", "paint")
spin_craft <- function(team_names) {
n_teams <- length(team_names)
if (n_teams > length(rooms) || n_teams > length(purpose) || n_teams > length(materials)) {
stop("Not enough unique items in one or more categories for the number of teams.")
}
set.seed(Sys.time())  # fresh randomness
sampled_rooms <- sample(rooms, n_teams)
sampled_purposes <- sample(purpose, n_teams)
sampled_materials <- sample(materials, n_teams)
results <- mapply(function(team, room, task, material) {
glue::glue("
ðŸ”§ **{team}** has been summoned by the ancient overlords of Tablith! Their quest:
â€¢ **Purpose:** Build a {task}
â€¢ **Location:** For the {room}
â€¢ **Material Constraint:** Must include {material}
May their glue guns be swift and their designs worthy.")
},
team = team_names,
room = sampled_rooms,
task = sampled_purposes,
material = sampled_materials,
SIMPLIFY = TRUE)
cat(paste(results, collapse = "\n\n"))
}
spin_craft(c("Just Ethan (actually totally 100% for real this time"))
library(progressr)
require(flexplot)
require(tidyverse)
require(party)
library(furrr)
require(sensitivity)
# monte carlo parameters --------------------------------------------------
sample_size   = c(100, 200, 400, 800, 1600)
causal_struc  = c("multiplicative", "cond_imp", "suppression", "local_only",
"signal_diff", "linear", "interaction")
# non-varying parameters --------------------------------------------------
betas = c(.8, .7, .6, .5, .4, 0, 0, 0, 0, 0)
nonlinear_coef = .5
iterations = 1000
# begin loop --------------------------------------------------------------
source("tools/monte_carlo_function.R")
handlers("txtprogressbar")
with_progress({
p = progressor(steps = iterations)
results_lm = future_map_dfr(
1:iterations,
~ {
res = n_1_monte_carlo(.x, betas = betas, sample_size = sample_size, causal_struc = causal_struc)
p()  # Tick progress bar
res
},
.options = furrr_options(seed = TRUE)
)
flush.console()
})
write.csv(results_lm, file="tests/data/monte_carlo.csv")
write.csv(results_lm, file="tools/data/monte_carlo.csv")
# how similar are my shap versus fastshap
flexplot(ji_shap~ji_mshap   | causal_struc, data=results_lm, method="lm")
flexplot(cor_shap~cor_mshap | causal_struc, data=results_lm, method="lm")
## compute difference between mine and shap
d = results_lm %>%
mutate(ji_bias  = ji_mshap - ji_shap,
cor_bias = cor_mshap- cor_shap,
time_diff= shap_time - megashap_time)
d$time_diff %>% as.numeric %>% hist()
flexplot(ji_bias~causal_struc, data=d)
flexplot(cor_bias~causal_struc, data=d)
flexplot(time_diff~causal_struc, data=d)
cor = matrix(.2, nrow=10, ncol=10)
cor
diag(cor) = 1
cor
rho
es  = runif(1, 0, .6)
rho = runif(1, 0, .9)
n   = sample(sample_size, size=1)
cs  = sample(causal_struc, size=1)
cor = matrix(.2, nrow=10, ncol=10)
diag(cor) = 1
cor[1,2] = cor[2,1] = rho
rho
cor[1,2] = cor[2,1] = rho
d = MASS::mvrnorm(n, rep(0, 10), cor) %>%
as.data.frame() %>%
setNames(paste0("x", 1:10))
cor
d = MASS::mvrnorm(n, rep(0, 10), cor) %>%
as.data.frame() %>%
setNames(paste0("x", 1:10))
str(d)
X1 = data.frame(matrix(runif(n * 10), ncol = 10))
X2 = data.frame(matrix(runif(n * 10), ncol = 10))
colnames(X1) = colnames(X2) = paste0("x", 1:10)
sob = sobol2002(model = fx_function, X1 = X1, X2 = X2, nboot = 0)
fx_function = make_fx_function(cs, betas)
fx = fx_function(d)
# Add residual noise
sigma_sq = var(fx) * (1 - es) / es
residuals = rnorm(n, 0, sqrt(sigma_sq))
d$y = fx + residuals
# Get "true" variable importances
X1 = data.frame(matrix(runif(n * 10), ncol = 10))
X2 = data.frame(matrix(runif(n * 10), ncol = 10))
colnames(X1) = colnames(X2) = paste0("x", 1:10)
sob = sobol2002(model = fx_function, X1 = X1, X2 = X2, nboot = 0)
true_importance = sob$T %>% as.vector %>% unlist# total Sobol indices
names(true_importance) = paste0("x", 1:10)
true_importance
cs
lm_mod = lm(y ~ ., data=d)
true_top     = order(true_importance, decreasing = TRUE)[1:5]
true_top
shap_vals
lm_mod = lm(y ~ ., data=d)
t1 = Sys.time()
shap_vals = fastshap::explain(lm_mod, X=d[-ncol(d)], nsim=50, exact=FALSE, pred_wrapper=predict.lm) %>%
abs() %>% colMeans()
t2 = Sys.time()
mega_shap = megashap(lm_mod, X=d[-ncol(d)], nsim=50, predict_function=predict.lm)
t3 = Sys.time()
true_top     = order(true_importance, decreasing = TRUE)[1:5]
shap_top     = order(shap_vals,     decreasing = TRUE)[1:5]
shap_vals
shap_top     = order(shap_vals,     decreasing = TRUE)[1:5]
shap_top
mshap_top    = order(mega_shap,     decreasing = TRUE)[1:5]
mshap_top
# compute jaccard
ji_shap  = length(intersect(true_top, shap_top)) / length(union(true_top, shap_top))
ji_mshap = length(intersect(true_top,mshap_top)) / length(union(true_top,mshap_top))
ji_shap
ji_mshap
true_importance
shap_vals
true_importance
mega_shap
# compute correlation
cor_shap  = cor(true_importance, shap_vals)
cor_mshap = cor(true_importance, mega_shap)
cor_shap
cor_mshap
head(results_lm)
str(results_lm)
str(results_lm)
# how similar are my shap versus fastshap
flexplot(ji_shap~ji_mshap   | causal_struc, data=results_lm, method="lm")
# how similar are my shap versus fastshap
flexplot(ji_shap~ji_mshap   | causal_struc, data=results_lm, method="lm", ghost.line="red")
flexplot(cor_shap~cor_mshap | causal_struc, data=results_lm, method="lm", ghost.line="red")
## compute difference between mine and shap
d = results_lm %>%
mutate(ji_bias  = ji_mshap - ji_shap,
cor_bias = cor_mshap- cor_shap,
time_diff= shap_time - megashap_time)
d$time_diff %>% as.numeric %>% hist()
d$time_diff %>% as.numeric %>% mean
flexplot(ji_bias~causal_struc, data=d)
flexplot(cor_bias~causal_struc, data=d)
head(results_lm)
plot_ready = results_lm %>%
pivot_longer(ji_shap:cor_mshap) %>%
mutate(name = factor(name))
